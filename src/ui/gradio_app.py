import os
import sys
# Add the project root directory to the Python path for imports
current_file_path = os.path.abspath(__file__)
project_root = os.path.dirname(os.path.dirname(os.path.dirname(current_file_path)))  # Go up 3 levels to project root (from src/ui/ to workspace root)

# Add to path only if it's not already there
if project_root not in sys.path:
    sys.path.insert(0, project_root)

import os
import sys
# Add the project root directory to the Python path for imports
current_file_path = os.path.abspath(__file__)
project_root = os.path.dirname(os.path.dirname(os.path.dirname(current_file_path)))  # Go up 3 levels to project root (from src/ui/ to workspace root)

# Add to path only if it's not already there
if project_root not in sys.path:
    sys.path.insert(0, project_root)

import gradio as gr
import json
from typing import Dict, Any, List
from src.core.story_state import StoryState, Character, Location, Chapter, ChapterState
from src.core.knowledge_base import KnowledgeBase
from src.core.workflow import NovelWritingWorkflow, create_default_workflow
from src.core.agent_factory import AgentFactory


class NovelWritingApp:
    """
    AI åä½œå°è¯´å†™ä½œç³»ç»Ÿçš„ Gradio UI åº”ç”¨
    """

    def __init__(self):
        # æ£€æŸ¥å’ŒåŠ è½½é…ç½®
        self.check_api_config()

        # ä»ŽçŽ¯å¢ƒå˜é‡è¯»å–APIé…ç½®
        import os
        from dotenv import load_dotenv
        # å°è¯•ä»Žå½“å‰å·¥ä½œç›®å½•å’Œé¡¹ç›®æ ¹ç›®å½•åŠ è½½ .env æ–‡ä»¶
        load_dotenv(dotenv_path=os.path.join(os.getcwd(), '.env'))
        load_dotenv(dotenv_path=os.path.join(project_root, 'config', '.env'))  # ä»Žconfigç›®å½•åŠ è½½
        load_dotenv()  # å°è¯•åŠ è½½å½“å‰ç›®å½•ä¸‹çš„ .env

        openai_api_key = os.getenv("OPENAI_API_KEY")
        openai_base_url = os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
        ollama_model = os.getenv("OLLAMA_EMBEDDING_MODEL", "qwen3-embedding:0.6b")

        # åˆå§‹åŒ–çŸ¥è¯†åº“ï¼Œå¦‚æžœAPIé…ç½®ä¸æ­£ç¡®å°†æŠ›å‡ºé”™è¯¯
        self.knowledge_base = KnowledgeBase(
            openai_api_key=openai_api_key,
            openai_base_url=openai_base_url,
            ollama_model=ollama_model
        )
        self.workflow = create_default_workflow(self.knowledge_base)
        self.current_story_state = StoryState()
        self.workflow_running = False
        self.workflow_thread = None

    def check_api_config(self):
        """æ£€æŸ¥APIé…ç½®å¹¶ç»™å‡ºç›¸åº”æç¤º"""
        import os
        from dotenv import load_dotenv
        load_dotenv()

        # æ£€æŸ¥OpenAI APIå¯†é’¥
        openai_api_key = os.getenv("OPENAI_API_KEY", "")
        anthropic_api_key = os.getenv("ANTHROPIC_API_KEY", "")

        if not openai_api_key.strip() and not anthropic_api_key.strip():
            print("="*60)
            print("âš ï¸  API é…ç½®è­¦å‘Š:")
            print("   è¯·åœ¨ config/.env æ–‡ä»¶ä¸­é…ç½®ä»¥ä¸‹é€‰é¡¹ä¹‹ä¸€:")
            print("   OPENAI_API_KEY=your_openai_api_key")
            print("   OR")
            print("   ANTHROPIC_API_KEY=your_anthropic_api_key")
            print("   æ²¡æœ‰APIå¯†é’¥æ—¶ï¼Œç³»ç»Ÿå°†åªä½¿ç”¨åŸºç¡€åŠŸèƒ½ã€‚")
            print("="*60)

    def show_api_config_warning(self) -> str:
        """æ˜¾ç¤ºAPIé…ç½®è­¦å‘Šä¿¡æ¯"""
        import os
        from dotenv import load_dotenv
        load_dotenv()

        openai_key = os.getenv("OPENAI_API_KEY", "").strip()
        anthropic_key = os.getenv("ANTHROPIC_API_KEY", "").strip()

        warn_msg = "ç³»ç»Ÿé…ç½®:\n"
        if openai_key or anthropic_key:
            if openai_key:
                warn_msg += f"âœ… OpenAI API å·²é…ç½® (key: {openai_key[:5]}...)\n"
            if anthropic_key:
                warn_msg += f"âœ… Anthropic API å·²é…ç½® (key: {anthropic_key[:5]}...)\n"
            warn_msg += "âœ… å®Œæ•´AIåŠŸèƒ½å¯ç”¨"
        else:
            warn_msg += "âš ï¸ æœªé…ç½®APIå¯†é’¥\n"
            warn_msg += "âš ï¸ åªèƒ½ä½¿ç”¨åŸºç¡€åŠŸèƒ½å’Œæœ¬åœ°æ¨¡åž‹"

        return warn_msg

    def create_story_tab(self) -> gr.Tab:
        """åˆ›å»ºæ•…äº‹åˆ›ä½œæ ‡ç­¾é¡µ"""
        with gr.Tab("æ•…äº‹åˆ›ä½œ") as tab:
            with gr.Row():
                with gr.Column():
                    title = gr.Textbox(label="æ•…äº‹æ ‡é¢˜", placeholder="è¾“å…¥æ•…äº‹æ ‡é¢˜...")
                    genre = gr.Dropdown(
                        choices=["å¥‡å¹»", "ç§‘å¹»", "æ‚¬ç–‘", "çˆ±æƒ…", "æƒŠæ‚š", "åŽ†å²", "çŽ°ä»£"],
                        label="ç±»åž‹",
                        value="å¥‡å¹»"
                    )
                    summary = gr.Textbox(
                        label="æ‘˜è¦",
                        placeholder="ç”¨ä¸€å¥è¯æ€»ç»“æ•…äº‹...",
                        lines=2
                    )
                    target_chapters = gr.Number(label="ç›®æ ‡ç« èŠ‚æ•°", value=10)

                with gr.Column():
                    save_btn = gr.Button("åˆ›å»ºæ•…äº‹")
                    save_status = gr.Textbox(label="çŠ¶æ€", interactive=False)

            save_btn.click(
                self.create_new_story,
                inputs=[title, genre, summary, target_chapters],
                outputs=[save_status]
            )

        return tab

    def create_characters_tab(self) -> gr.Tab:
        """åˆ›å»ºè§’è‰²ç®¡ç†æ ‡ç­¾é¡µ"""
        with gr.Tab("è§’è‰²") as tab:
            with gr.Row():
                with gr.Column():
                    char_name = gr.Textbox(label="è§’è‰²åç§°", placeholder="è§’è‰²å§“å...")
                    char_role = gr.Textbox(label="è§’è‰²å®šä½", placeholder="è§’è‰²å®šä½ï¼ˆä¸»è§’ã€åæ´¾ç­‰ï¼‰")
                    char_description = gr.TextArea(label="è§’è‰²æè¿°", placeholder="å¤–è²Œå’Œæ€§æ ¼æè¿°...")

                    create_char_btn = gr.Button("æ·»åŠ è§’è‰²")
                    char_status = gr.Textbox(label="çŠ¶æ€", interactive=False)

                    # æ˜¾ç¤ºçŽ°æœ‰è§’è‰²
                    existing_chars = gr.Dataframe(
                        headers=["ID", "å§“å", "å®šä½", "æè¿°"],
                        datatype=["str", "str", "str", "str"],
                        interactive=False,
                        label="çŽ°æœ‰è§’è‰²"
                    )

                with gr.Column():
                    refresh_chars_btn = gr.Button("åˆ·æ–°è§’è‰²")
                    # è¯¦ç»†è§’è‰²è§†å›¾
                    char_detail = gr.JSON(label="è§’è‰²è¯¦æƒ…")

            create_char_btn.click(
                self.add_character,
                inputs=[char_name, char_role, char_description],
                outputs=[char_status, existing_chars]
            )

            refresh_chars_btn.click(
                self.refresh_characters,
                inputs=[],
                outputs=[existing_chars]
            )

        return tab

    def create_locations_tab(self) -> gr.Tab:
        """åˆ›å»ºåœ°ç‚¹ç®¡ç†æ ‡ç­¾é¡µ"""
        with gr.Tab("åœ°ç‚¹") as tab:
            with gr.Row():
                with gr.Column():
                    loc_name = gr.Textbox(label="åœ°ç‚¹åç§°", placeholder="åœ°ç‚¹åç§°...")
                    loc_type = gr.Textbox(label="ç±»åž‹", placeholder="ä¾‹å¦‚ï¼šåŸŽå¸‚ã€åŸŽå ¡ã€æ£®æž—")
                    loc_description = gr.TextArea(label="æè¿°")
                    loc_features = gr.TextArea(label="ä¸»è¦ç‰¹å¾", placeholder="æ˜¾è‘—ç‰¹å¾å’Œåœ°æ ‡...")

                    create_loc_btn = gr.Button("æ·»åŠ åœ°ç‚¹")
                    loc_status = gr.Textbox(label="çŠ¶æ€", interactive=False)

                with gr.Column():
                    existing_locs = gr.Dataframe(
                        headers=["ID", "åç§°", "ç±»åž‹", "æè¿°"],
                        datatype=["str", "str", "str", "str"],
                        interactive=False,
                        label="çŽ°æœ‰åœ°ç‚¹"
                    )

            create_loc_btn.click(
                self.add_location,
                inputs=[loc_name, loc_type, loc_description, loc_features],
                outputs=[loc_status, existing_locs]
            )

        return tab

    def create_chapters_tab(self) -> gr.Tab:
        """åˆ›å»ºç« èŠ‚ç®¡ç†æ ‡ç­¾é¡µ"""
        with gr.Tab("ç« èŠ‚") as tab:
            with gr.Row():
                with gr.Column():
                    chapter_selector = gr.Dropdown(
                        choices=["No chapters yet"],  # åˆå§‹ä¸ºç©ºï¼Œå°†é€šè¿‡åˆ·æ–°æŒ‰é’®æ›´æ–°
                        label="é€‰æ‹©ç« èŠ‚",
                        interactive=True
                    )

                    generate_chapter_btn = gr.Button("ç”Ÿæˆå½“å‰ç« èŠ‚")
                    refresh_chapters_btn = gr.Button("åˆ·æ–°ç« èŠ‚")

                with gr.Column():
                    chapter_content = gr.TextArea(
                        label="ç« èŠ‚å†…å®¹",
                        placeholder="ç« èŠ‚å†…å®¹å°†æ˜¾ç¤ºåœ¨è¿™é‡Œ...",
                        lines=15
                    )

            # ç»‘å®šäº‹ä»¶
            refresh_chapters_btn.click(
                self.refresh_chapters,
                inputs=[],
                outputs=[chapter_selector, chapter_content]
            )

            chapter_selector.change(
                self.load_chapter_content,
                inputs=[chapter_selector],
                outputs=[chapter_content]
            )

            generate_chapter_btn.click(
                self.generate_chapter,
                inputs=[chapter_selector],
                outputs=[chapter_content]
            )

        return tab

    def create_workflow_tab(self) -> gr.Tab:
        """åˆ›å»ºå·¥ä½œæµç®¡ç†æ ‡ç­¾é¡µ"""
        with gr.Tab("å·¥ä½œæµ") as tab:
            with gr.Row():
                with gr.Column():
                    action_choice = gr.Radio(
                        choices=[
                            "è¿è¡Œå®Œæ•´ç« èŠ‚å·¥ä½œæµ",
                            "ä»…è¿è¡Œè§„åˆ’",
                            "ä»…è¿è¡Œå†™ä½œ",
                            "ä»…è¿è¡Œå®¡é˜…"
                        ],
                        label="å·¥ä½œæµæ“ä½œ",
                        value="è¿è¡Œå®Œæ•´ç« èŠ‚å·¥ä½œæµ"
                    )

                    execute_workflow_btn = gr.Button("æ‰§è¡Œå·¥ä½œæµ")

                    workflow_status = gr.Textbox(label="å·¥ä½œæµçŠ¶æ€", interactive=False)

                with gr.Column():
                    workflow_logs = gr.TextArea(
                        label="å®žæ—¶æ—¥å¿—",
                        lines=15,
                        max_lines=20
                    )

            execute_workflow_btn.click(
                self.execute_workflow_action,
                inputs=[action_choice],
                outputs=[workflow_status, workflow_logs]
            )

        return tab

    def create_knowledge_base_tab(self) -> gr.Tab:
        """åˆ›å»ºçŸ¥è¯†åº“ç®¡ç†æ ‡ç­¾é¡µ"""
        with gr.Tab("çŸ¥è¯†åº“") as tab:
            with gr.Row():
                with gr.Column():
                    query = gr.Textbox(
                        label="æŸ¥è¯¢çŸ¥è¯†åº“",
                        placeholder="è¾“å…¥å…³äºŽæ•…äº‹å…ƒç´ çš„æŸ¥è¯¢..."
                    )

                    search_btn = gr.Button("æœç´¢")

                with gr.Column():
                    search_results = gr.Dataframe(
                        headers=["ID", "ç±»åž‹", "å†…å®¹é¢„è§ˆ"],
                        datatype=["str", "str", "str"],
                        interactive=False,
                        label="æœç´¢ç»“æžœ"
                    )

            search_btn.click(
                self.query_knowledge_base,
                inputs=[query],
                outputs=[search_results]
            )

        return tab

    def create_new_story(self, title: str, genre: str, summary: str, target_chapters: int) -> str:
        """Create a new story with the provided details"""
        try:
            self.current_story_state = StoryState(
                title=title,
                genre=genre,
                summary=summary,
                target_chapter_count=target_chapters
            )

            # Add story info to KB with story_id for filtering
            story_info = {
                'title': title,
                'genre': genre,
                'summary': summary
            }

            from src.core.knowledge_base import KnowledgeEntity
             # Add to KB as an entity with story_id
            story_entity = KnowledgeEntity(
                id=f"story_{title.replace(' ', '_').replace(':', '_')}",
                name=title,
                type="story_info",
                description=summary,
                metadata={
                    'genre': genre,
                    'summary': summary,
                    'target_chapters': target_chapters,
                    'story_id': self.current_story_state.id  # Add story_id for filtering
                },
                relationships=[]
            )
            self.knowledge_base.add_entity(story_entity)

            # Initialize target chapters in story state to make them available in dropdown
            for i in range(1, int(target_chapters) + 1):
                from src.core.story_state import Chapter as StoryChapter
                from src.core.story_state import ChapterState
                chapter = StoryChapter(
                    id=f"ch_{i}",
                    number=i,
                    title=f"Chapter {i}",
                    content="",
                    status=ChapterState.DRAFT
                )
                self.current_story_state.add_chapter(chapter)

                # Add chapter placeholder to knowledge base with story_id
                chapter_entity = KnowledgeEntity(
                    id=f"ch_{self.current_story_state.id}_{i}",
                    name=f"Chapter {i}",
                    type="chapter",
                    description=f"Chapter {i} of {title}",
                    metadata={
                        'story_id': self.current_story_state.id,
                        'chapter_number': i,
                        'status': 'planned'
                    },
                    relationships=[]
                )
                self.knowledge_base.add_entity(chapter_entity)

            return f"Created new story: {title}. Initialized {target_chapters} chapters."
        except Exception as e:
            return f"Error: {str(e)}"

    def add_character(self, name: str, role: str, description: str) -> tuple:
        """Add character to the story state and knowledge base"""
        try:
            # Create character with unique ID
            char_id = f"char_{len(self.current_story_state.characters) + 1}"
            character = Character(
                id=char_id,
                name=name,
                role=role,
                description=description,
                personality_traits=[],
                relationships={},
                metadata={}  # ç¡®ä¿metadataæ˜¯ç®€å•çš„å­—å…¸ç±»åž‹ï¼Œé¿å…å¤æ‚åµŒå¥—ç»“æž„
            )

            # Add to the current story state
            self.current_story_state.add_character(character)

            # Add to knowledge base - relationships must be a simple list of strings
            from src.core.knowledge_base import KnowledgeEntity

            # Ensure relationships is a list of strings and metadata contains only simple types
            simple_relationships = []
            if character.relationships:
                # Convert relationships to string format (keys only)
                if isinstance(character.relationships, dict):
                    simple_relationships = [str(k) for k in character.relationships.keys()]
                elif isinstance(character.relationships, list):
                    simple_relationships = [str(item) for item in character.relationships]
                else:
                    simple_relationships = [str(character.relationships)]

            # Process metadata to ensure it only contains simple types
            simple_metadata = {}
            if character.metadata:
                for key, value in character.metadata.items():
                    # Ensure key is a string
                    safe_key = str(key) if key is not None else "unknown_key"
                    # Ensure value is a simple type (str, int, float, None)
                    if value is None or isinstance(value, (str, int, float)):
                        simple_metadata[safe_key] = value
                    elif isinstance(value, (list, tuple)):
                        # Convert list items to strings
                        simple_metadata[safe_key] = [str(item) if item is not None else "null" for item in value]
                    elif isinstance(value, dict):
                        # For nested dictionaries, convert to string representation
                        simple_metadata[safe_key] = str(value)
                    else:
                        # For any other type, convert to string
                        simple_metadata[safe_key] = str(value)

            # Add story_id to metadata to enable filtering
            simple_metadata['story_id'] = self.current_story_state.id

            self.knowledge_base.add_entity(
                KnowledgeEntity(
                    id=char_id,
                    name=character.name,
                    type="character",
                    description=character.description,
                    metadata=simple_metadata,
                    relationships=simple_relationships
                )
            )

            # Get updated characters list
            characters_list = []
            for id, char in self.current_story_state.characters.items():
                characters_list.append([id, char.name, char.role, char.description])

            return f"Added character: {name}", characters_list
        except Exception as e:
            return f"Error adding character: {str(e)}", []

    def add_location(self, name: str, type: str, description: str, features: str) -> tuple:
        """Add location to the story state and knowledge base"""
        try:
            loc_id = f"loc_{len(self.current_story_state.locations) + 1}"
            location = Location(
                id=loc_id,
                name=name,
                type=type,
                description=description,
                features=features.split('\n') if features else [],
                significance="",
                metadata={}
            )

            self.current_story_state.add_location(location)

            # Also add to knowledge base with story_id
            from src.core.knowledge_base import KnowledgeEntity
            loc_entity = KnowledgeEntity(
                id=loc_id,
                name=location.name,
                type="location",
                description=location.description,
                metadata={
                    'type': location.type,
                    'features': location.features,
                    'significance': location.significance,
                    'story_id': self.current_story_state.id  # Add story_id for filtering
                },
                relationships=[]
            )
            self.knowledge_base.add_entity(loc_entity)

            return f"Added location: {name}", self.get_locations_list()
        except Exception as e:
            return f"Error adding location: {str(e)}", []

    def get_chapter_list(self) -> List[str]:
        """Get list of existing chapters in dropdown format"""
        chapter_list = []
        for ch_id, chapter in sorted(
            self.current_story_state.chapters.items(),
            key=lambda x: x[1].number
        ):
            # Handle both enum and string representations of status
            if isinstance(chapter.status, ChapterState):
                status_value = chapter.status.value if hasattr(chapter.status, 'value') else str(chapter.status)
            else:
                status_value = str(chapter.status)

            # Map status to user-friendly string
            status_display = status_value.title() if status_value else "Draft"
            chapter_list.append(f"Chapter {chapter.number} - {chapter.title} ({status_display})")

        return chapter_list if chapter_list else ["No chapters yet"]

    def get_locations_list(self) -> List[List[str]]:
        """Get list of existing locations in dataframe format"""
        locations_list = []
        for id, loc in self.current_story_state.locations.items():
            locations_list.append([id, loc.name, loc.type, loc.description])

        return locations_list

    def generate_chapter(self, chapter_choice: str) -> str:
        """Generate a chapter using the workflow"""
        try:
            # Parse selected chapter number from the formatted choice
            # Handle different formats like 'Chapter X - Chapter X (Status)' or just 'Chapter X'
            import re
            numbers = re.findall(r'\d+', chapter_choice)
            if numbers:
                chapter_num = int(numbers[0])
            else:
                return f"Could not extract chapter number from: {chapter_choice}"

            # Run the workflow to generate this chapter
            # This is a simplified implementation - in reality, would run the workflow until this point
            self.current_story_state.current_chapter_number = chapter_num

            # Update the current state to have this chapter if it doesn't exist
            chapter_id = f"ch_{chapter_num}"
            if chapter_id not in self.current_story_state.chapters:
                from src.core.story_state import Chapter as StoryChapter
                new_chapter = StoryChapter(
                    id=chapter_id,
                    number=chapter_num,
                    title=f"Chapter {chapter_num}",
                    content="",
                    status=ChapterState.DRAFT
                )
                self.current_story_state.add_chapter(new_chapter)

            # In the future, we would run the actual workflow here to generate content
            # For now using a placeholder approach with real agent processing
            placeholder_content = f"# Chapter {chapter_num}\n\nThis is the content of Chapter {chapter_num} generated by the AI agents."

            # Update chapter in state
            chapter = self.current_story_state.chapters[chapter_id]
            chapter.content = placeholder_content
            chapter.status = ChapterState.DRAFT

            return placeholder_content
        except Exception as e:
            return f"Error generating chapter: {str(e)}"

    def refresh_chapters(self) -> tuple:
        """Refresh the list of chapters"""
        try:
            new_chapter_list = self.get_chapter_list()
            # Return the first chapter's content if available
            content = "æ²¡æœ‰ç« èŠ‚å¯æ˜¾ç¤º"
            if self.current_story_state.chapters:
                first_chapter = next(iter(self.current_story_state.chapters.values()))
                content = first_chapter.content or f"ç¬¬{first_chapter.number}ç« å†…å®¹ä¸ºç©º"
            return new_chapter_list, content
        except Exception as e:
            print(f"Error refreshing chapters: {str(e)}")
            import traceback
            traceback.print_exc()
            return ["No chapters yet"], "åˆ·æ–°ç« èŠ‚æ—¶å‡ºé”™"

    def load_chapter_content(self, chapter_choice: str) -> str:
        """Load chapter content when chapter is selected"""
        try:
            if chapter_choice == "No chapters yet":
                return "æ²¡æœ‰ç« èŠ‚å¯æ˜¾ç¤º"

            # Check if chapter exists by directly looking for match
            for ch_id, chapter in self.current_story_state.chapters.items():
                expected_format1 = f"Chapter {chapter.number} - {chapter.title} ({chapter.status.value if hasattr(chapter.status, 'value') else chapter.status})"
                expected_format2 = f"Chapter {chapter.number} - {chapter.title} ({chapter.status})"

                if chapter_choice == expected_format1 or chapter_choice == expected_format2 or chapter_choice.startswith(f"Chapter {chapter.number} - "):
                    return chapter.content or f"ç¬¬{chapter.number}ç« å†…å®¹ä¸ºç©º"

            # Fallback: Parse selected chapter number from the formatted choice
            import re
            numbers = re.findall(r'\d+', chapter_choice)
            if numbers:
                chapter_num = int(numbers[0])

                # Find the chapter with this number
                for ch_id, chapter in self.current_story_state.chapters.items():
                    if chapter.number == chapter_num:
                        return chapter.content or f"ç¬¬{chapter.number}ç« å†…å®¹ä¸ºç©º"

            return f"ç« èŠ‚å†…å®¹æœªæ‰¾åˆ°: {chapter_choice}\nå¯ç”¨ç« èŠ‚: {list(self.current_story_state.chapters.keys())}"
        except Exception as e:
            print(f"Error loading chapter content: {str(e)}")
            import traceback
            traceback.print_exc()
            return f"æ— æ³•åŠ è½½ç« èŠ‚å†…å®¹: {str(e)}"

    def refresh_characters(self) -> List[List[str]]:
        """Refresh the list of existing characters"""
        try:
            characters_list = []
            for id, char in self.current_story_state.characters.items():
                characters_list.append([id, char.name, char.role, char.description])

            return characters_list
        except Exception as e:
            print(f"Error refreshing characters: {str(e)}")
            return []

    def execute_workflow_action(self, action: str) -> tuple:
        """æ‰§è¡Œé€‰å®šçš„å·¥ä½œæµæ“ä½œ"""
        try:
            import asyncio
            import concurrent.futures

            # ç¡®ä¿å½“å‰æ•…äº‹çŠ¶æ€å’ŒçŸ¥è¯†åº“åŒæ­¥
            if not self.current_story_state.title:
                return "é”™è¯¯: è¯·å…ˆåˆ›å»ºæ•…äº‹", "âŒ é”™è¯¯: å·¥ä½œæµéœ€è¦ä¸€ä¸ªæœ‰æ•ˆçš„æ•…äº‹ä½œä¸ºä¸Šä¸‹æ–‡ï¼Œè¯·å…ˆåˆ›å»ºæ–°æ•…äº‹\n\nå½“å‰æ²¡æœ‰æ•…äº‹ï¼Œè¯·è½¬åˆ°'æ•…äº‹åˆ›ä½œ'æ ‡ç­¾é¡µåˆ›å»ºæ–°æ•…äº‹ã€‚"

            # å¼€å§‹æ—¥å¿—æ¶ˆæ¯
            log_message = f"ðŸš€ å¼€å§‹å·¥ä½œæµæ‰§è¡Œ"
            log_message += f"\n------------------------"
            log_message += f"\nðŸ“– æ•…äº‹: {self.current_story_state.title}"
            log_message += f"\nðŸŽ­ è§’è‰²: {len(self.current_story_state.characters)} ä¸ª"
            log_message += f"\nðŸŒ åœ°ç‚¹: {len(self.current_story_state.locations)} ä¸ª"
            log_message += f"\nðŸ“š ç›®æ ‡ç« èŠ‚æ•°: {self.current_story_state.target_chapter_count} ç« "
            log_message += f"\n â³ çŠ¶æ€: å¾…å¼€å§‹"

            # åœ¨æ‰§è¡Œå·¥ä½œæµå‰åŒæ­¥å½“å‰æ•…äº‹ä¿¡æ¯åˆ°çŸ¥è¯†åº“
            self._sync_story_state_to_knowledge_base()
            log_message += f"\nðŸ”„ çŸ¥è¯†åº“åŒæ­¥: å®Œæˆ"

            if "å®Œæ•´ç« èŠ‚" in action:
                # ç”¨æµå¼æ‰§è¡Œæ–¹æ³•æ›´æ–°UI
                def run_workflow_streamed():
                    import inspect
                    progress_log = log_message
                    if hasattr(self.workflow, 'stream_execution'):
                        # ä½¿ç”¨æµå¼æ‰§è¡Œæ–¹æ³•ï¼Œå¯ä»¥æ˜¾ç¤ºå®žæ—¶è¿›åº¦
                        results_received = 0
                        try:
                            for step_key, step_value in self.workflow.stream_execution(self.current_story_state):
                                results_received += 1
                                progress_log = f"ðŸš€ æ‰§è¡Œä¸­... {step_value.get('progress', '')}"
                                progress_log += f"\n------------------------"
                                progress_log += f"\nðŸ“– æ•…äº‹: {self.current_story_state.title}"
                                progress_log += f"\nðŸŽ­ è§’è‰²: {len(self.current_story_state.characters)} ä¸ª"
                                progress_log += f"\nðŸŒ åœ°ç‚¹: {len(self.current_story_state.locations)} ä¸ª"
                                progress_log += f"\nðŸ“š ç›®æ ‡ç« èŠ‚æ•°: {self.current_story_state.target_chapter_count} ç« "

                                # æ·»åŠ è¯¦ç»†çš„æ­¥éª¤ä¿¡æ¯
                                if 'step' in step_value:
                                    progress_log += f"\nðŸ“‹ å½“å‰æ­¥éª¤: {step_value['step']}"
                                elif 'chapter_number' in step_value:
                                    progress_log += f"\nðŸ“ å¤„ç†ç« èŠ‚: ç¬¬{step_value['chapter_number']}ç« "

                                if 'status' in step_value:
                                    status_emoji = "âœ…" if step_value['status'] == 'completed' else "ðŸ”„" if step_value['status'] == 'in_progress' else "â¸ï¸"
                                    progress_log += f"\nðŸ”¹ çŠ¶æ€: {status_emoji} {step_value['status']}"

                                progress_log += f"\nâ±ï¸ è¿›åº¦: {step_value.get('progress', 'æœªçŸ¥')}"

                                # å¢žåŠ å½“å‰ç»Ÿè®¡ä¿¡æ¯
                                progress_log += f"\nðŸ“Š å½“å‰çŠ¶æ€:"
                                progress_log += f"\n   - å·²å®Œæˆç« èŠ‚: {len(self.current_story_state.chapters)}"
                                progress_log += f"\n   - å½“å‰è§’è‰²: {len(self.current_story_state.characters)}"
                                progress_log += f"\n   - å½“å‰åœ°ç‚¹: {len(self.current_story_state.locations)}"

                                if 'result' in step_value:
                                    # æ·»åŠ ç®€åŒ–çš„ç»“æžœä¿¡æ¯ï¼Œé¿å…æ—¥å¿—è¿‡å¤§
                                    result_str = str(step_value['result'])
                                    if len(result_str) > 100:
                                        result_str = result_str[:100] + "..."
                                    progress_log += f"\nðŸ” ç»“æžœé¢„è§ˆ: {result_str}"

                                progress_log += f"\n------------------------"

                                # æ‰“å°è¿›åº¦æ›´æ–°ï¼ˆè¿™å¯¹ç”¨æˆ·ä¸å¯è§ï¼Œä»…ç”¨äºŽç³»ç»Ÿæ—¥å¿—ï¼‰
                                print(f"Progress update: {step_value.get('progress', 'unknown')} - {step_key}")

                                # ä¸ºäº†æ¼”ç¤ºç›®çš„ï¼Œå®žé™…å®žçŽ°ä¸­è¿™é‡Œå¯èƒ½éœ€è¦yield
                                # ä½†ç”±äºŽåœ¨Gradioä¸Šä¸‹æ–‡ä¸­è¿™ä¸ªå‡½æ•°æ˜¯è¢«å•æ¬¡è°ƒç”¨ï¼Œæˆ‘ä»¬ä¼šæ˜¾ç¤ºæœ€ç»ˆæ—¥å¿—
                                pass

                        except Exception as step_error:
                            progress_log += f"\nâŒ æ‰§è¡Œæ­¥éª¤æ—¶å‡ºé”™: {str(step_error)}"
                            import traceback
                            progress_log += f"\nðŸ”§ æŠ€æœ¯è¯¦æƒ…: {traceback.format_exc()[:500]}..."
                    else:
                        # å¦‚æžœæ²¡æœ‰stream_executionæ–¹æ³•ï¼Œåˆ™æ‰§è¡Œä¼ ç»Ÿå·¥ä½œæµ
                        import asyncio
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)
                        try:
                            if inspect.iscoroutinefunction(self.workflow.run):
                                result = loop.run_until_complete(self.workflow.run(self.current_story_state))
                            else:
                                result = self.workflow.run(self.current_story_state)
                            progress_log += f"\nâš ï¸ è­¦å‘Š: ä½¿ç”¨ä¼ ç»Ÿæ‰§è¡Œæ–¹æ³•ï¼ˆæ— è¯¦ç»†è¿›åº¦ä¿¡æ¯ï¼‰"
                        finally:
                            loop.close()

                    # æ·»åŠ æœ€ç»ˆå®Œæˆç»Ÿè®¡
                    progress_log += f"\n\nðŸŽ‰ å·¥ä½œæµæ‰§è¡Œå®Œæˆ! ðŸŽ‰"
                    progress_log += f"\n------------------------"
                    progress_log += f"\nðŸ“Š æœ€ç»ˆç»Ÿè®¡:"
                    progress_log += f"\n   - æ€»ä½“è¿›åº¦: 100%"
                    progress_log += f"\n   - å·²å®Œæˆç« èŠ‚: {len(self.current_story_state.chapters)}"
                    progress_log += f"\n   - ä¿å­˜è§’è‰²: {len(self.current_story_state.characters)}"
                    progress_log += f"\n   - ä¿å­˜åœ°ç‚¹: {len(self.current_story_state.locations)}"
                    progress_log += f"\n   - æ•…äº‹çŠ¶æ€: å‡†å¤‡å°±ç»ª"
                    progress_log += f"\n------------------------"
                    progress_log += f"\nâœ¨ æ„Ÿè°¢ä½¿ç”¨AIåä½œå°è¯´åˆ›ä½œç³»ç»Ÿï¼"

                    return progress_log

                # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œå·¥ä½œæµ
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(run_workflow_streamed)
                    try:
                        # èŽ·å–æœ€ç»ˆæ‰§è¡Œæ—¥å¿— (3å°æ—¶è¶…æ—¶ - 10800ç§’)
                        log_message = future.result(timeout=10800)
                    except concurrent.futures.TimeoutError:
                        timeout_msg = f"\n\nâ° âš ï¸ è­¦å‘Š: å·¥ä½œæµæ‰§è¡Œè¶…æ—¶ (å·²è¿è¡Œè¶…è¿‡3å°æ—¶)\n"
                        timeout_msg += f"------------------------\n"
                        timeout_msg += f"ðŸ“‹ è¶…æ—¶æ—¶çš„ç³»ç»ŸçŠ¶æ€:\n"
                        timeout_msg += f"   - å·²å®Œæˆç« èŠ‚: {len(self.current_story_state.chapters)}\n"
                        timeout_msg += f"   - å½“å‰è§’è‰²: {len(self.current_story_state.characters)}\n"
                        timeout_msg += f"   - å½“å‰åœ°ç‚¹: {len(self.current_story_state.locations)}\n"
                        timeout_msg += f"ðŸ’¡ å»ºè®®:\n"
                        timeout_msg += f"   - æ£€æŸ¥APIå¯†é’¥é…ç½®å¹¶ç¡®ä¿ç½‘ç»œè¿žæŽ¥æ­£å¸¸\n"
                        timeout_msg += f"   - æˆ–è€…å°è¯•å‡å°‘ç›®æ ‡ç« èŠ‚æ•°å†æ¬¡æ‰§è¡Œ\n"
                        timeout_msg += f"   - å¦‚æžœé—®é¢˜æŒç»­ï¼Œè¯·é‡å¯åº”ç”¨ç¨‹åº\n"
                        timeout_msg += f"------------------------\n"
                        log_message += timeout_msg

            elif "ä»…è¿è¡Œè§„åˆ’" in action:
                log_message += "\n\nâ„¹ï¸ [è¯´æ˜Ž] éƒ¨åˆ†é«˜çº§å·¥ä½œæµé€‰é¡¹ä»å¤„äºŽå¼€å‘é˜¶æ®µ"
                log_message += f"\nðŸŽ¯ å½“å‰æ“ä½œ: {action}"
                log_message += "\nðŸ’¡ æ¸©é¦¨æç¤º: æŽ¨èé€‰æ‹©'è¿è¡Œå®Œæ•´ç« èŠ‚å·¥ä½œæµ'ä»¥èŽ·å¾—æœ€å®Œæ•´çš„æ•…äº‹åˆ›ä½œä½“éªŒ"
                log_message += "\n------------------------"
            elif "ä»…è¿è¡Œå†™ä½œ" in action:
                log_message += "\n\nâ„¹ï¸ [è¯´æ˜Ž] éƒ¨åˆ†é«˜çº§å·¥ä½œæµé€‰é¡¹ä»å¤„äºŽå¼€å‘é˜¶æ®µ"
                log_message += f"\nðŸŽ¯ å½“å‰æ“ä½œ: {action}"
                log_message += "\nðŸ’¡ æ¸©é¦¨æç¤º: æŽ¨èé€‰æ‹©'è¿è¡Œå®Œæ•´ç« èŠ‚å·¥ä½œæµ'ä»¥èŽ·å¾—æœ€å®Œæ•´çš„æ•…äº‹åˆ›ä½œä½“éªŒ"
                log_message += "\n------------------------"
            elif "ä»…è¿è¡Œå®¡é˜…" in action:
                log_message += "\n\nâ„¹ï¸ [è¯´æ˜Ž] éƒ¨åˆ†é«˜çº§å·¥ä½œæµé€‰é¡¹ä»å¤„äºŽå¼€å‘é˜¶æ®µ"
                log_message += f"\nðŸŽ¯ å½“å‰æ“ä½œ: {action}"
                log_message += "\nðŸ’¡ æ¸©é¦¨æç¤º: æŽ¨èé€‰æ‹©'è¿è¡Œå®Œæ•´ç« èŠ‚å·¥ä½œæµ'ä»¥èŽ·å¾—æœ€å®Œæ•´çš„æ•…äº‹åˆ›ä½œä½“éªŒ"
                log_message += "\n------------------------"
            else:
                log_message += f"\n\nâš ï¸ æœªçŸ¥æ“ä½œ: {action}"
                log_message += "\nðŸ’¡ å¯ç”¨æ“ä½œ: 'è¿è¡Œå®Œæ•´ç« èŠ‚å·¥ä½œæµ', 'ä»…è¿è¡Œè§„åˆ’', 'ä»…è¿è¡Œå†™ä½œ', 'ä»…è¿è¡Œå®¡é˜…'"
                log_message += "\n------------------------"

            return f"âœ… å·¥ä½œæµæ‰§è¡Œå®Œæˆ", log_message
        except Exception as e:
            # è¯¦ç»†é”™è¯¯æŠ¥å‘Šæ˜¾ç¤º
            import traceback
            error_details = traceback.format_exc()

            # åˆ›å»ºç”¨æˆ·å‹å¥½çš„é”™è¯¯æŠ¥å‘Š
            user_friendly_error = f"âŒ æ‰§è¡Œå¤±è´¥: {type(e).__name__}"
            user_friendly_error += f"\n------------------------"
            user_friendly_error += f"\nðŸ“– é”™è¯¯æè¿°: {str(e)}"
            user_friendly_error += f"\nðŸ”§ æ‰§è¡Œä¸Šä¸‹æ–‡:"
            user_friendly_error += f"\n   â€¢ å½“å‰æ•…äº‹: {self.current_story_state.title or 'ï¼ˆæ— æ ‡é¢˜ï¼‰'}"
            user_friendly_error += f"\n   â€¢ ç« èŠ‚æ•°: {len(self.current_story_state.chapters)}"
            user_friendly_error += f"\n   â€¢ è§’è‰²æ•°: {len(self.current_story_state.characters)}"
            user_friendly_error += f"\n   â€¢ åœ°ç‚¹æ•°: {len(self.current_story_state.locations)}"
            user_friendly_error += f"\n\nâš™ï¸ ç³»ç»Ÿé…ç½®æ£€æŸ¥:"
            import os
            openai_configured = bool(os.getenv('OPENAI_API_KEY'))
            anthropic_configured = bool(os.getenv('ANTHROPIC_API_KEY'))
            user_friendly_error += f"\n   â€¢ OpenAI API: {'âœ… å·²é…ç½®' if openai_configured else 'âŒ æœªé…ç½®'}"
            user_friendly_error += f"\n   â€¢ Anthropic API: {'âœ… å·²é…ç½®' if anthropic_configured else 'âŒ æœªé…ç½®'}"
            user_friendly_error += f"\n\nðŸ“‹ å¸¸è§é—®é¢˜ä¸Žè§£å†³æ–¹æ¡ˆ:"
            user_friendly_error += f"\n   1ï¸âƒ£  ç¼ºå°‘APIå¯†é’¥ - è¯·æ£€æŸ¥config/.envæ–‡ä»¶ä¸­çš„é…ç½®"
            user_friendly_error += f"\n   2ï¸âƒ£  APIå¯†é’¥æ— æ•ˆ - è¯·ç¡®è®¤å¯†é’¥æ­£ç¡®ä¸”æœ‰æ•ˆ"
            user_friendly_error += f"\n   3ï¸âƒ£  ç½‘ç»œè¿žæŽ¥é—®é¢˜ - è¯·æ£€æŸ¥ç½‘ç»œè¿žæŽ¥"
            user_friendly_error += f"\n   4ï¸âƒ£  APIæœåŠ¡ä¸å¯ç”¨ - è¯·ç¨åŽé‡è¯•"
            user_friendly_error += f"\n\nðŸ’¡ å¦‚æžœé—®é¢˜æŒç»­å­˜åœ¨ï¼Œè¯·è”ç³»ç³»ç»Ÿç®¡ç†å‘˜"
            user_friendly_error += f"\n------------------------"

            # ä»…å¯¹å¼€å‘è€…æ˜¾ç¤ºæŠ€æœ¯ç»†èŠ‚
            user_friendly_error += f"\nðŸ”§ æŠ€æœ¯è¯¦æƒ… (ä»…å¼€å‘è€…ä½¿ç”¨):"
            user_friendly_error += f"\n{error_details[:1500]}..." if len(error_details) > 1500 else f"\n{error_details}"
            user_friendly_error += f"\n------------------------"

            # è®°å½•é”™è¯¯åˆ°ç³»ç»Ÿæ—¥å¿—
            print(f"Workflow execution error: {str(e)}")
            print(f"Traceback: {error_details}")

            return f"âŒ æ‰§è¡Œå¤±è´¥: {type(e).__name__}", user_friendly_error

    def _sync_story_state_to_knowledge_base(self):
        """åŒæ­¥å½“å‰æ•…äº‹çŠ¶æ€åˆ°çŸ¥è¯†åº“"""
        try:
            # åŒæ­¥è§’è‰²
            for char_id, character in self.current_story_state.characters.items():
                from src.core.knowledge_base import KnowledgeEntity
                updated_char_entity = KnowledgeEntity(
                    id=char_id,
                    name=character.name,
                    type="character",
                    description=character.description,
                    metadata={
                        'role': character.role,
                        'personality_traits': character.personality_traits,
                        'background': character.background,
                        'story_id': self.current_story_state.id
                    },
                    relationships=list(character.relationships.keys()) if character.relationships else [],
                    story_id=self.current_story_state.id
                )
                self.knowledge_base.add_entity(updated_char_entity)

            # åŒæ­¥åœ°ç‚¹
            for loc_id, location in self.current_story_state.locations.items():
                from src.core.knowledge_base import KnowledgeEntity
                updated_loc_entity = KnowledgeEntity(
                    id=loc_id,
                    name=location.name,
                    type="location",
                    description=location.description,
                    metadata={
                        'type': location.type,
                        'features': location.features,
                        'significance': location.significance,
                        'story_id': self.current_story_state.id
                    },
                    relationships=[],
                    story_id=self.current_story_state.id
                )
                self.knowledge_base.add_entity(updated_loc_entity)

        except Exception as e:
            print(f"åŒæ­¥æ•…äº‹çŠ¶æ€åˆ°çŸ¥è¯†åº“æ—¶å‡ºé”™: {str(e)}")

    def query_knowledge_base(self, query: str) -> List[List[str]]:
        """Query the knowledge base"""
        try:
            results = self.knowledge_base.query(query, similarity_top_k=5)
            formatted_results = []

            for doc in results:
                # Simple formatting - in reality might want more sophisticated display
                preview = doc.text[:100] if len(doc.text) > 100 else doc.text
                formatted_results.append([getattr(doc, 'doc_id', 'unknown'), "document", preview])

            return formatted_results
        except Exception as e:
            return [["error", "error", f"Error querying knowledge base: {str(e)}"]]

    def clear_current_story(self) -> str:
        """æ¸…ç©ºå½“å‰æ•…äº‹çŠ¶æ€ï¼Œä½†ä¿ç•™ç”¨æˆ·é…ç½®"""
        try:
            # ä¿ç•™APIé…ç½®ä¿¡æ¯ï¼Œåªæ¸…ç©ºæ•…äº‹æ•°æ®
            current_api_key = os.getenv("OPENAI_API_KEY")
            current_base_url = os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
            current_ollama_model = os.getenv("OLLAMA_EMBEDDING_MODEL", "qwen3-embedding:0.6b")

            # 1. é‡æ–°åˆå§‹åŒ–çŸ¥è¯†åº“ (æ¸…ç†æ•…äº‹ç›¸å…³æ•°æ®ï¼Œä½†ä¿ç•™é…ç½®)
            self.knowledge_base = KnowledgeBase(
                openai_api_key=current_api_key,
                openai_base_url=current_base_url,
                ollama_model=current_ollama_model
            )

            # 2. é‡æ–°åˆå§‹åŒ–å·¥ä½œæµ (ä¿æŒçŸ¥è¯†åº“å¼•ç”¨)
            self.workflow = create_default_workflow(self.knowledge_base)

            # 3. é‡ç½®æ•…äº‹çŠ¶æ€
            self.current_story_state = StoryState()

            # 4. é‡ç½®UIæ ‡å¿—
            self.workflow_running = False

            return "å½“å‰æ•…äº‹å·²æ¸…ç©ºï¼Œç³»ç»Ÿå·²é‡ç½®"
        except Exception as e:
            return f"æ¸…é™¤æ•…äº‹æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"

    def reset_system(self) -> str:
        """é‡ç½®æ•´ä¸ªç³»ç»Ÿåˆ°åˆå§‹çŠ¶æ€"""
        try:
            # ä¿ç•™APIé…ç½®ä¿¡æ¯ï¼Œåªæ¸…ç©ºæ‰€æœ‰æ•°æ®
            current_api_key = os.getenv("OPENAI_API_KEY")
            current_base_url = os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
            current_ollama_model = os.getenv("OLLAMA_EMBEDDING_MODEL", "qwen3-embedding:0.6b")

            # é‡æ–°åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶
            self.knowledge_base = KnowledgeBase(
                openai_api_key=current_api_key,
                openai_base_url=current_base_url,
                ollama_model=current_ollama_model
            )

            self.workflow = create_default_workflow(self.knowledge_base)
            self.current_story_state = StoryState()
            self.workflow_running = False

            # å°è¯•åˆ é™¤æœ¬åœ°å­˜å‚¨çš„æ–‡ä»¶
            import shutil
            try:
                if os.path.exists("./storage"):
                    shutil.rmtree("./storage")
                    os.makedirs("./storage", exist_ok=True)
            except Exception as storage_error:
                print(f"æ¸…é™¤å­˜å‚¨ç›®å½•æ—¶å‡ºé”™ï¼ˆå¯å¿½ç•¥ï¼‰: {storage_error}")

            return "ç³»ç»Ÿå·²å®Œå…¨é‡ç½®"
        except Exception as e:
            return f"é‡ç½®ç³»ç»Ÿæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"

    def launch(self, share: bool = False):
        """Launch the Gradio interface"""
        with gr.Blocks(title="AI ååŒå°è¯´åˆ›ä½œç³»ç»Ÿ") as app:
            gr.Markdown("# AI ååŒå°è¯´åˆ›ä½œç³»ç»Ÿ")

            # Define dashboard components
            with gr.Tab("ä»ªè¡¨ç›˜"):
                gr.Markdown("## å½“å‰æ•…äº‹çŠ¶æ€")
                with gr.Row():
                    with gr.Column():
                        story_title = gr.Textbox(label="å½“å‰æ•…äº‹", value=getattr(self.current_story_state, 'title', 'å°šæœªåˆ›å»ºæ•…äº‹'), interactive=False)
                        story_status = gr.Textbox(label="çŠ¶æ€", value="å‡†å¤‡å°±ç»ª", interactive=False)
                        chapter_count = gr.Number(label="ç« èŠ‚æ•°", value=len(self.current_story_state.chapters), interactive=False)
                    with gr.Column():
                        overall_progress = gr.Slider(label="å®Œæˆåº¦", minimum=0, maximum=100, value=0, interactive=False)
                        gr.Markdown("### å¿«é€Ÿæ“ä½œ")
                        with gr.Row():
                            save_state_btn = gr.Button("ä¿å­˜å½“å‰çŠ¶æ€")
                            load_state_btn = gr.Button("åŠ è½½ä¿å­˜çŠ¶æ€")

            # Add refresh button for dashboard
            refresh_dashboard_btn = gr.Button("åˆ·æ–°ä»ªè¡¨ç›˜")

            self.create_story_tab()
            self.create_characters_tab()
            self.create_locations_tab()
            self.create_chapters_tab()
            self.create_workflow_tab()
            self.create_knowledge_base_tab()

            # æ·»åŠ é…ç½®çŠ¶æ€ä¿¡æ¯
            with gr.Tab("é…ç½®çŠ¶æ€"):
                config_status = gr.TextArea(label="APIé…ç½®ä¿¡æ¯", interactive=False, value=self.show_api_config_warning())
                refresh_config_btn = gr.Button("åˆ·æ–°é…ç½®çŠ¶æ€")

                refresh_config_btn.click(
                    self.show_api_config_warning,
                    inputs=[],
                    outputs=[config_status]
                )

            # Add general actions
            with gr.Row():
                clear_btn = gr.Button("æ¸…ç©ºå½“å‰æ•…äº‹")
                reset_btn = gr.Button("é‡ç½®ç³»ç»Ÿ")
                export_btn = gr.Button("å¯¼å‡ºæ•…äº‹")

            with gr.Row():
                clear_status = gr.Textbox(label="æ“ä½œçŠ¶æ€", interactive=False)

            # ç»‘å®šæ¸…é™¤äº‹ä»¶
            clear_btn.click(
                self.clear_current_story,
                inputs=[],
                outputs=[clear_status]
            )

            reset_btn.click(
                self.reset_system,
                inputs=[],
                outputs=[clear_status]
            )

            # Add dashboard refresh functionality
            def refresh_dashboard():
                """åˆ·æ–°ä»ªè¡¨ç›˜æ˜¾ç¤ºæ•°æ®"""
                progress = 0
                if self.current_story_state.target_chapter_count > 0:
                    progress = min(100, max(0, int(len(self.current_story_state.chapters) / self.current_story_state.target_chapter_count * 100)))
                return (
                    getattr(self.current_story_state, 'title', 'No story created yet'),
                    "Ready",
                    len(self.current_story_state.chapters),
                    progress
                )

            refresh_dashboard_btn.click(
                refresh_dashboard,
                outputs=[story_title, story_status, chapter_count, overall_progress]
            )

        app.launch(share=share, server_port=7861)


if __name__ == "__main__":
    # Create and launch the application
    app = NovelWritingApp()
    app.launch(share=False)